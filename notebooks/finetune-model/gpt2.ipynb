{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning GPT-2 for text classification\n",
    "Stefan/Yuzhao Heng\n",
    "Since Wed. Feb. 9th, 2022\n",
    "\n",
    "\n",
    "Reproduce the results in paper [Zero-shot Text Classification With Generative Language Models](https://arxiv.org/abs/1912.10165),\n",
    "since the authors didn't release the code.\n",
    "\n",
    "Serve as infrastructure and baseline for project on efficient and accurate encoder for text classification with many labels.\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from icecream import ic\n",
    "\n",
    "\n",
    "from util import *\n",
    "\n",
    "\n",
    "transformers.set_seed(config('random-seed'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/stefanh/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b3411f72c9d4796a5344c72cec9e7b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dset: {'test': Dataset({\n",
      "              features: ['text', 'label'],\n",
      "              num_rows: 7600\n",
      "          }),\n",
      "           'train': Dataset({\n",
      "              features: ['text', 'label'],\n",
      "              num_rows: 120000\n",
      "          })}\n",
      "ic| isinstance(model, torch.nn.Module): True\n",
      "ic| model.parameters(): <generator object Module.parameters at 0x7f82b6005e40>\n",
      "ic| model_param_size(model): '124M'\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f58c176d38e94629b3f58a3c779c0ffd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.42G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8dea3b9fee74a00bd192e5d8ee3ad0e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| model_param_size(AutoModel.from_pretrained('gpt2-medium')): '355M'\n"
     ]
    },
    {
     "data": {
      "text/plain": "'355M'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnm = 'ag_news'\n",
    "dset = load_dataset(dnm)\n",
    "ic(dset)\n",
    "\n",
    "\n",
    "model_nm, model_nm_lg = 'gpt2', 'gpt2-medium'  # Models used in the paper, parameter sizes: 124M, 355M; TODO: discrepancy with Open AI reported number?\n",
    "model = AutoModel.from_pretrained(model_nm)\n",
    "# ic(model, type(model))\n",
    "\n",
    "ic(isinstance(model, torch.nn.Module))\n",
    "ic(model.parameters())\n",
    "\n",
    "\n",
    "def model_param_size(m: torch.nn.Module) -> str:\n",
    "   return fmt_num(sum(p.numel() for p in m.parameters()))\n",
    "\n",
    "ic(model_param_size(model))\n",
    "ic(model_param_size(AutoModel.from_pretrained('gpt2-medium')))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}