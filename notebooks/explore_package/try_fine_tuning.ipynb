{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Try fine-tuning `Sentence BERT`\n",
    "Since Thur. Dec. 9th, 2021\n",
    "\n",
    "To set up our fine-tuning pipeline\n",
    "\n",
    "To verify our implementation, check if we can reproduce the results from [*Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks*](https://arxiv.org/abs/1908.10084).\n",
    "With Hugging Face dependency, not [sentence-transformers](https://github.com/UKPLab/sentence-transformers).\n",
    "\n",
    "Specifically, on **section 4.2 Supervised STS**, go with `SBERT-STSb-base`:\n",
    "> The STS benchmark (STSb) (Cer et al., 2017) provides is a popular dataset to evaluate supervised STS systems.\n",
    "\n",
    "> We use the training set to fine-tune SBERT using the regression objective function. At prediction time, we compute the cosine-similarity between the sentence embeddings. All systems are trained with 10 random seeds to counter variances.\n",
    "\n",
    "An example on [sentence-transformers](https://github.com/UKPLab/sentence-transformers):\n",
    "    [training_stsbenchmark.py](https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark.py).\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from icecream import ic\n",
    "\n",
    "from util import *\n",
    "\n",
    "\n",
    "name_tune = 'eg_sbert'\n",
    "d_tune = config(f'fine-tune.{name_tune}')\n",
    "dnm = d_tune[\"dataset_name\"]\n",
    "d_dset = config(f'datasets.{dnm}')\n",
    "md_path = os.path.join(PATH_BASE, DIR_MDL, name_tune)\n",
    "mdnm = d_tune['embedding_model_name']\n",
    "\n",
    "seed = config('random-seed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check STSb data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset stsb_multi_mt (/Users/stefanh/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7cc9adb3d5e4ac8a5e8720c400e86b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dset: {'dev': Dataset({\n",
      "              features: ['sentence1', 'sentence2', 'similarity_score'],\n",
      "              num_rows: 1500\n",
      "          }),\n",
      "           'test': Dataset({\n",
      "              features: ['sentence1', 'sentence2', 'similarity_score'],\n",
      "              num_rows: 1379\n",
      "          }),\n",
      "           'train': Dataset({\n",
      "              features: ['sentence1', 'sentence2', 'similarity_score'],\n",
      "              num_rows: 5749\n",
      "          })}\n",
      "ic| len(dset['train']): 5749\n",
      "    dset['train'][0]: {'sentence1': 'A plane is taking off.',\n",
      "                       'sentence2': 'An air plane is taking off.',\n",
      "                       'similarity_score': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": "(5749,\n {'sentence1': 'A plane is taking off.',\n  'sentence2': 'An air plane is taking off.',\n  'similarity_score': 5.0})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = load_dataset(dnm, name='en')\n",
    "ic(dset)\n",
    "ic(len(dset['train']), dset['train'][0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check BERT model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tokenizer: PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(mdnm)\n",
    "ic(tokenizer)\n",
    "\n",
    "model = AutoModel.from_pretrained(mdnm)\n",
    "assert str(model.__class__) == \"<class 'transformers.models.bert.modeling_bert.BertModel'>\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}