{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Try fine-tuning `Sentence BERT`\n",
    "Since Thur. Dec. 9th, 2021\n",
    "\n",
    "To set up our fine-tuning pipeline\n",
    "\n",
    "To verify our implementation, check if we can reproduce the results from [*Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks*](https://arxiv.org/abs/1908.10084).\n",
    "With Hugging Face dependency, not [sentence-transformers](https://github.com/UKPLab/sentence-transformers).\n",
    "\n",
    "Specifically, on **section 4.2 Supervised STS**, go with `SBERT-STSb-base`:\n",
    "> The STS benchmark (STSb) (Cer et al., 2017) provides is a popular dataset to evaluate supervised STS systems.\n",
    "\n",
    "> We use the training set to fine-tune SBERT using the regression objective function. At prediction time, we compute the cosine-similarity between the sentence embeddings. All systems are trained with 10 random seeds to counter variances.\n",
    "\n",
    "An example on [sentence-transformers](https://github.com/UKPLab/sentence-transformers):\n",
    "    [training_stsbenchmark.py](https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark.py).\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from icecream import ic\n",
    "\n",
    "\n",
    "dnm = 'stsb_multi_mt'\n",
    "mdnm = 'bert-base-uncased'\n",
    "seed = 77\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check STSb data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset stsb_multi_mt (/Users/stefanh/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/bc6de0eaa8d97c28a4c22a07e851b05879ae62c60b0b69dd6b331339e8020f07)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "634f1faab35d496c9630b38bffeb9ff3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dset: {'dev': Dataset({\n",
      "              features: ['sentence1', 'sentence2', 'similarity_score'],\n",
      "              num_rows: 1500\n",
      "          }),\n",
      "           'test': Dataset({\n",
      "              features: ['sentence1', 'sentence2', 'similarity_score'],\n",
      "              num_rows: 1379\n",
      "          }),\n",
      "           'train': Dataset({\n",
      "              features: ['sentence1', 'sentence2', 'similarity_score'],\n",
      "              num_rows: 5749\n",
      "          })}\n",
      "ic| len(dset['train']): 5749\n",
      "    dset['train'][0]: {'sentence1': 'A plane is taking off.',\n",
      "                       'sentence2': 'An air plane is taking off.',\n",
      "                       'similarity_score': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": "(5749,\n {'sentence1': 'A plane is taking off.',\n  'sentence2': 'An air plane is taking off.',\n  'similarity_score': 5.0})"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = load_dataset(dnm, name='en')\n",
    "ic(dset)\n",
    "# ic(dset['dev'])\n",
    "\n",
    "# for split in ['dev', 'train', 'test']:\n",
    "#     dset = load_dataset(dnm, name='en', split=split)\n",
    "#     ic(dset)\n",
    "\n",
    "ic(len(dset['train']), dset['train'][0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check BERT model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f014755e5e484f7184a6b072ac65c88b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "616775616bde4204aaf42e949c3072e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78458e64a53440979e18dc53e21d3d1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba77aeecbcf44580921c940702a50fdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tokenizer: PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e74a2bbeb7a4e4bae4ba2427e2d32d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "ic| model.__class__: <class 'transformers.models.bert.modeling_bert.BertModel'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "transformers.models.bert.modeling_bert.BertModel"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(mdnm)\n",
    "ic(tokenizer)\n",
    "\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained(mdnm)\n",
    "ic(model.__class__)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}